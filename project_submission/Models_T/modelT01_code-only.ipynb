{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# TWO FOLDERS UP\n",
    "data_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir, 'data'))\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "train_dirs = []\n",
    "for i in range(1, 5):\n",
    "    train_dirs.append(os.path.join(train_dir, 'train' + str(i)))\n",
    "\n",
    "validation_dir = os.path.join(data_dir, 'train', 'train5')\n",
    "\n",
    "print(current_dir)\n",
    "print(data_dir)\n",
    "print(test_dir)\n",
    "print(train_dir)\n",
    "print(validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load training datasets from train1 to train4\n",
    "train_datasets = []\n",
    "IMG_SIZE = 150\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "for i in range(1, 5):\n",
    "    dataset = image_dataset_from_directory(train_dirs[i-1], image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical')\n",
    "    train_datasets.append(dataset)\n",
    " \n",
    "train_dataset = train_datasets[0]\n",
    "for dataset in train_datasets[1:]:\n",
    "    train_dataset = train_dataset.concatenate(dataset)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical')\n",
    "\n",
    "\n",
    "test_dataset = image_dataset_from_directory(test_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical')\n",
    "\n",
    "class_names = validation_dataset.class_names\n",
    "class_names = [class_name.split('_')[-1] for class_name in class_names]\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for data, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        plt.imshow(data[i].numpy().astype('uint8'))\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "base_model.trainable = False  # Freeze the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# import numpy as np\n",
    "\n",
    "# def get_features_and_labels(dataset):\n",
    "#     all_features = []\n",
    "#     all_labels = []\n",
    "#     for images, labels in dataset:\n",
    "#         preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "#         features = base_model.predict(preprocessed_images)\n",
    "#         all_features.append(features)\n",
    "#         all_labels.append(labels)\n",
    "#     return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "\n",
    "# validation_features, validation_labels = get_features_and_labels(validation_dataset)\n",
    "# np.save('validation_features.npy', validation_features)\n",
    "# np.save('validation_labels.npy', validation_labels)\n",
    "# validation_features = None\n",
    "# validation_labels = None\n",
    "# print(\"Validation features and labels saved\")\n",
    "\n",
    "# test_features, test_labels = get_features_and_labels(test_dataset)\n",
    "# np.save('test_features.npy', test_features)\n",
    "# np.save('test_labels.npy', test_labels)\n",
    "# test_features = None\n",
    "# test_labels = None\n",
    "# print(\"Test features and labels saved\")\n",
    "\n",
    "# train_features, train_labels = get_features_and_labels(train_dataset)\n",
    "# np.save('train_features.npy', train_features)\n",
    "# np.save('train_labels.npy', train_labels)\n",
    "# train_features = None\n",
    "# train_labels = None\n",
    "# print(\"Train features and labels saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "\n",
    "train_features = load('features_T/train_features.npy')\n",
    "train_labels = load('features_T/train_labels.npy')\n",
    "\n",
    "validation_features = load('features_T/validation_features.npy')\n",
    "validation_labels = load('features_T/validation_labels.npy')\n",
    "\n",
    "test_features = load('features_T/test_features.npy')\n",
    "test_labels = load('features_T/test_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Architecture:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.applications import VGG16\n",
    "from keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(4, 4, 512))\n",
    "\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)  # Softmax for multi-class classification\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_acc', \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    factor=0.5, \n",
    "    min_lr=1e-6)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', \n",
    "                           patience=5,\n",
    "                           restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('models/T01/checkpoints/T01-cp.h5', save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=50,\n",
    "    validation_data=(validation_features, validation_labels),\n",
    "    callbacks=[early_stop, model_checkpoint, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(model, 'models/T01/T01-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.load_model('models/T01/T01-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(validation_features, validation_labels)\n",
    "print('val_acc:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the history from the training process\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = np.argmax(model.predict(validation_features), axis=1)\n",
    "y_true = np.argmax(validation_labels, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# Load an image\n",
    "img_path = train_dirs[0] + '/006_frog/alytes_obstetricans_s_000179.png'\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(150, 150), interpolation='bilinear')\n",
    "\n",
    "# Preprocess the image for VGG16\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(img_array.shape)\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Extract features using VGG16\n",
    "features = base_model.predict(img_array)\n",
    "\n",
    "flattened_features = features.reshape((features.shape[0], -1))\n",
    "\n",
    "# Predict using your custom model\n",
    "result = model.predict(flattened_features)\n",
    "\n",
    "print(\"Result: \", result.round())\n",
    "print(\"Predicted class: \", class_names[np.argmax(result)])\n",
    "print(\"True class: \", img_path.split('/')[-2].split('_')[-1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
