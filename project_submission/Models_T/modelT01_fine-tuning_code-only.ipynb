{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# TWO FOLDERS UP\n",
    "data_dir = os.path.abspath(os.path.join(current_dir, os.pardir, os.pardir, 'data'))\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "train_dirs = []\n",
    "for i in range(1, 5):\n",
    "    train_dirs.append(os.path.join(train_dir, 'train' + str(i)))\n",
    "\n",
    "validation_dir = os.path.join(data_dir, 'train', 'train5')\n",
    "\n",
    "print(current_dir)\n",
    "print(data_dir)\n",
    "print(test_dir)\n",
    "print(train_dir)\n",
    "print(validation_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load training datasets from train1 to train4\n",
    "train_datasets = []\n",
    "IMG_SIZE = 150\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "for i in range(1, 5):\n",
    "    dataset = image_dataset_from_directory(train_dirs[i-1], image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical')\n",
    "    train_datasets.append(dataset)\n",
    " \n",
    "train_dataset = train_datasets[0]\n",
    "for dataset in train_datasets[1:]:\n",
    "    train_dataset = train_dataset.concatenate(dataset)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical')\n",
    "\n",
    "\n",
    "test_dataset = image_dataset_from_directory(test_dir, image_size=(IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE, label_mode='categorical')\n",
    "\n",
    "class_names = validation_dataset.class_names\n",
    "class_names = [class_name.split('_')[-1] for class_name in class_names]\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for data, _ in train_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        plt.imshow(data[i].numpy().astype('uint8'))\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('models/T01/T01-DA-model.h5')\n",
    "\n",
    "val_loss, val_acc = model.evaluate(validation_dataset)\n",
    "print('val_acc:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convbase = model.get_layer(\"vgg16\")\n",
    "convbase.trainable = True\n",
    "\n",
    "# Unfreeze the last 4 layers\n",
    "for layer in convbase.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for i, layer in enumerate(convbase.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_acc', \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    factor=0.5, \n",
    "    min_lr=1e-6)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_acc', \n",
    "                           patience=4,\n",
    "                           restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('models/T01/checkpoints/T01-FT-cp.h5', save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=15,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=[early_stop, model_checkpoint, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(model, 'models/T01/T01-FT-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.load_model('models/T01/T01-FT-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(validation_dataset)\n",
    "print('val_acc:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the history from the training process\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Plot the training and validation accuracy\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the training and validation loss\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for data, labels in test_dataset:\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(model.predict(data), axis=-1))\n",
    "    \n",
    "y_true = np.argmax(y_true, axis=-1)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Load an image\n",
    "img = tf.keras.preprocessing.image.load_img(train_dirs[0] + '/006_frog/alytes_obstetricans_s_000179.png', target_size=(150, 150), interpolation='bilinear')\n",
    "# img = tf.keras.preprocessing.image.load_img(train_dirs[0] + '/000_airplane/airbus_s_000012.png', target_size=(32, 32), interpolation='bilinear')\n",
    "\n",
    "# Preprocess the image\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(img_array.shape)\n",
    "result = model.predict(img_array)\n",
    "print(\"Result: \", result.round())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
